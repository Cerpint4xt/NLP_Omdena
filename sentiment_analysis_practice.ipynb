{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis practice for NLP_Omdena\n",
    "Name: Raul Catacora Grundy\n",
    "\n",
    "email: rcatagrundy@gmail.com\n",
    "\n",
    "repository: https://github.com/Cerpint4xt/NLP_Omdena\n",
    "\n",
    "## Installing dependencies to run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.12.0-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.4 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 41.0/60.4 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.4/60.4 kB 401.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\rcata\\anaconda3\\envs\\nlp_omdena\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.1.post1-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/10.6 MB 3.6 MB/s eta 0:00:03\n",
      "    --------------------------------------- 0.3/10.6 MB 3.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/10.6 MB 2.9 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.5/10.6 MB 2.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/10.6 MB 2.8 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/10.6 MB 2.8 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.9/10.6 MB 2.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/10.6 MB 2.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.1/10.6 MB 2.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.2/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.4/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.5/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.6/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.0/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.1/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.3/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.4/10.6 MB 2.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.5/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.6/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.8/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.0/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.3/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.4/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.5/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.6/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.8/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.0/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.2/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.3/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.4/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.6/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.6/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.8/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.9/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.0/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.1/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.2/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.4/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.5/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.6/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.7/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.8/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.0/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.1/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.2/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.4/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.6/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.7/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.8/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.9/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.1/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.2/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.3/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.4/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.5/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.8/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.0/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.1/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.3/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.4/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.5/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.6/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.8/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.9/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.0/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.3/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.5/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.6/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.7/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.9/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.0/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.1/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.3/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading scipy-1.12.0-cp310-cp310-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/46.2 MB 3.6 MB/s eta 0:00:13\n",
      "   ---------------------------------------- 0.3/46.2 MB 2.8 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 0.4/46.2 MB 2.8 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 0.5/46.2 MB 3.1 MB/s eta 0:00:15\n",
      "    --------------------------------------- 0.6/46.2 MB 2.8 MB/s eta 0:00:17\n",
      "    --------------------------------------- 0.8/46.2 MB 2.8 MB/s eta 0:00:17\n",
      "    --------------------------------------- 0.9/46.2 MB 2.8 MB/s eta 0:00:17\n",
      "    --------------------------------------- 1.0/46.2 MB 2.8 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.2/46.2 MB 2.7 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 1.3/46.2 MB 2.8 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.4/46.2 MB 2.7 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 1.6/46.2 MB 2.7 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 1.6/46.2 MB 2.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 1.8/46.2 MB 2.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 1.9/46.2 MB 2.7 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 2.0/46.2 MB 2.7 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 2.1/46.2 MB 2.6 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 2.3/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 2.4/46.2 MB 2.6 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 2.5/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 2.6/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 2.8/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 2.9/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 3.0/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 3.1/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 3.3/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 3.4/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.5/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.6/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.7/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 3.8/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 4.0/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 4.1/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 4.2/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 4.3/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 4.4/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 4.5/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 4.7/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 4.8/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 4.9/46.2 MB 2.6 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 5.1/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 5.2/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 5.3/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 5.4/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 5.6/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 5.7/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 5.8/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.0/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.1/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.2/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.3/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.5/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.6/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.7/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 6.9/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 7.0/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 7.1/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 7.2/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 7.3/46.2 MB 2.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 7.5/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 7.6/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 7.8/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 7.9/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 8.0/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.1/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.2/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.3/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.4/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.5/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.6/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.8/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.9/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 9.0/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 9.1/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 9.2/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 9.3/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 9.5/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 9.6/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 9.7/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 9.8/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 10.0/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 10.1/46.2 MB 2.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 10.3/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 10.4/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 10.4/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 10.6/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 10.7/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 10.8/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 10.8/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 10.9/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 11.1/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 11.2/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 11.3/46.2 MB 2.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 11.4/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 11.5/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 11.6/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 11.7/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 11.8/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 11.9/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 12.0/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 12.1/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 12.2/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 12.3/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 12.5/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 12.6/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 12.7/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 12.8/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 13.0/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 13.0/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 13.1/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 13.3/46.2 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 13.4/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 13.5/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 13.6/46.2 MB 2.4 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 13.8/46.2 MB 2.4 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 13.9/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 14.0/46.2 MB 2.4 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 14.2/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 14.3/46.2 MB 2.5 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 14.4/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 14.5/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 14.6/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 14.7/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 14.9/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 15.0/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.1/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.2/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.3/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.5/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.6/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.7/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.8/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.9/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 16.0/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 16.1/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 16.2/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 16.4/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 16.5/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 16.6/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 16.7/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 16.9/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 17.0/46.2 MB 2.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 17.1/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 17.2/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 17.4/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 17.5/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 17.6/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 17.7/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 17.8/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 18.0/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 18.1/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 18.2/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 18.2/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 18.3/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 18.3/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 18.4/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 18.4/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 18.6/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 18.7/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 18.8/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 19.0/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 19.1/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 19.2/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 19.3/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 19.4/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 19.6/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 19.7/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 19.8/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 19.9/46.2 MB 2.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 20.0/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 20.2/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 20.3/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 20.4/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 20.5/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 20.6/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 20.7/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 20.8/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 21.0/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 21.1/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 21.2/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 21.4/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 21.5/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 21.6/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 21.7/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 21.9/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 22.0/46.2 MB 2.4 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 22.1/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 22.3/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 22.3/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 22.5/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 22.6/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 22.7/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 22.8/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 23.0/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 23.1/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 23.2/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 23.4/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 23.5/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 23.6/46.2 MB 2.5 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 23.7/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 23.9/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 24.0/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 24.1/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 24.2/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 24.3/46.2 MB 2.4 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 24.5/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 24.6/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 24.7/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 24.8/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 24.9/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 25.1/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 25.2/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 25.3/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 25.4/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 25.6/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 25.7/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 25.8/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 25.9/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 26.1/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 26.2/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 26.3/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 26.4/46.2 MB 2.4 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 26.5/46.2 MB 2.5 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 26.7/46.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 26.8/46.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 26.9/46.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 27.0/46.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 27.2/46.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 27.2/46.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 27.3/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 27.4/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 27.5/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 27.7/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 27.8/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 27.9/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 28.1/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 28.2/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 28.3/46.2 MB 2.4 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 28.5/46.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 28.6/46.2 MB 2.5 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 28.7/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------ --------------- 28.8/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 28.9/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 29.1/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 29.2/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 29.3/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 29.5/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 29.6/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 29.7/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 29.9/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 29.9/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 30.1/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 30.2/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 30.3/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 30.4/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 30.5/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 30.6/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 30.8/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 30.9/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 31.0/46.2 MB 2.5 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 31.1/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 31.3/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 31.4/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 31.5/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 31.6/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 31.8/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 31.9/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 32.0/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 32.1/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 32.3/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 32.4/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 32.5/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 32.6/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 32.7/46.2 MB 2.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 32.9/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 33.0/46.2 MB 2.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 33.1/46.2 MB 2.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 33.3/46.2 MB 2.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 33.4/46.2 MB 2.6 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 33.5/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 33.7/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 33.8/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 33.9/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 34.0/46.2 MB 2.6 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 34.1/46.2 MB 2.6 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 34.2/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 34.3/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 34.5/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 34.6/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 34.7/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 34.9/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 35.0/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 35.1/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 35.2/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 35.2/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 35.4/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 35.5/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 35.7/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 35.7/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 35.9/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 36.0/46.2 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 36.1/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 36.3/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 36.4/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 36.5/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 36.6/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 36.8/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 36.9/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.0/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.1/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.3/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.3/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.4/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.6/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.7/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.8/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 37.8/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 38.0/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 38.1/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 38.1/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.2/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.2/46.2 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.3/46.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.3/46.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.4/46.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.5/46.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.6/46.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.7/46.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.8/46.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 38.9/46.2 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 39.0/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 39.2/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 39.3/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 39.4/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 39.6/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 39.6/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 39.8/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 39.9/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 39.9/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 40.0/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 40.2/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 40.3/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 40.4/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 40.5/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 40.6/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 40.7/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 40.9/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 41.0/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 41.1/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 41.2/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 41.3/46.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 41.5/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.6/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.7/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.8/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.0/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.1/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.3/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.4/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.5/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.6/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 42.7/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.8/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.0/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.1/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.2/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.3/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.5/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.6/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.7/46.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 43.8/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.1/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.2/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.3/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.5/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.6/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.7/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.8/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 45.0/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.1/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.2/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.3/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.5/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.6/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.7/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.0/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.0/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n",
    "Creating helper function to process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean\n",
    "\n",
    "\n",
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download sample for twitter and for stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to import nltk\n",
    "import nltk\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\rcata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\twitter_samples.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rcata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add folder, tmp2, from our local workspace containing pre-downloaded corpora files to nltk's data path\n",
    "# this enables importing of these files without downloading it again when we refresh our workspace\n",
    "\n",
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "* The `twitter_samples` contains subsets of 5,000 positive tweets, 5,000 negative tweets, and the full set of 10,000 tweets.  \n",
    "    * If you used all three datasets, we would introduce duplicates of the positive tweets and negative tweets.  \n",
    "    * You will select just the five thousand positive tweets and five thousand negative tweets.# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into two pieces, one for training and one for testing (validation set) \n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine positive and negative labels\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape train and test sets\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the frequency dictionary using the imported `build_freqs()` function.  \n",
    "    * We highly recommend that you open `utils.py` and read the `build_freqs()` function to understand what it is doing.\n",
    "    * To view the file directory, go to the menu and click File->Open.\n",
    "\n",
    "```Python\n",
    "    for y,tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "```\n",
    "* Notice how the outer for loop goes through each tweet, and the inner for loop steps through each word in a tweet.\n",
    "* The `freqs` dictionary is the frequency dictionary that's being built. \n",
    "* The key is the tuple (word, label), such as (\"happy\",1) or (\"happy\",0).  The value stored for each key is the count of how many times the word \"happy\" was associated with a positive label, or how many times \"happy\" was associated with a negative label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11337\n"
     ]
    }
   ],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process tweet\n",
    "The given function `process_tweet()` tokenizes the tweet into individual words, removes stop words and applies stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of a positive tweet: \n",
      " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n",
      "This is an example of the processed version of the tweet: \n",
      " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "# test the function below\n",
    "print('This is an example of a positive tweet: \\n', train_x[0])\n",
    "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "#### Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining sigmoid function\n",
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    '''\n",
    "    \n",
    "    # calculate the sigmoid of z\n",
    "    h = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\n",
      "CORRECT!\n"
     ]
    }
   ],
   "source": [
    "# Testing your function \n",
    "if (sigmoid(0) == 0.5):\n",
    "    print('SUCCESS!')\n",
    "else:\n",
    "    print('Oops!')\n",
    "\n",
    "if (sigmoid(4.92) == 0.9927537604041685):\n",
    "    print('CORRECT!')\n",
    "else:\n",
    "    print('Oops again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function and Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976294"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that when the model predicts close to 1, but the actual label is 0, the loss is a large positive value\n",
    "-1 * (1 - 0) * np.log(1 - 0.9999) # loss is about 9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976182"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that when the model predicts close to 0 but the actual label is 1, the loss is a large positive value\n",
    "-1 * np.log(0.0001) # loss is about 9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining gradien descent\n",
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    # get 'm', the number of rows in matrix x\n",
    "    m = len(x)\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x,theta)\n",
    "        \n",
    "        # get the sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # calculate the cost function\n",
    "        J = float(-1/m)*(np.dot(np.transpose(y),np.log(h))+np.dot(np.transpose(1-y),np.log(1-h)))\n",
    "    \n",
    "        # update the weights theta\n",
    "        theta = theta-((alpha/m)*np.dot(np.transpose(x),(h-y))) \n",
    "        \n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.67094970.\n",
      "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_11676\\1617959076.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "# Construct a synthetic test case using numpy PRNG functions\n",
    "np.random.seed(1)\n",
    "# X input is 10 x 3 with ones for the bias terms\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Y Labels are 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Apply gradient descent\n",
    "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word,1.0),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word,0.0),0)\n",
    "        \n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00e+00 3.02e+03 6.10e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Check your function\n",
    "\n",
    "# test 1\n",
    "# test on training data\n",
    "tmp1 = extract_features(train_x[0], freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "# check for when the words are not in the freqs dictionary\n",
    "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.24215478.\n",
      "The resulting vector of weights is [7e-08, 0.00052391, -0.00055517]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_11676\\694178799.py:34: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the logistic regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet, freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    y_pred = sigmoid(np.dot(x,theta))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.518581\n",
      "I am bad -> 0.494339\n",
      "this movie should have been great. -> 0.515331\n",
      "great -> 0.515464\n",
      "great great -> 0.530899\n",
      "great great great -> 0.546274\n",
      "great great great great -> 0.561562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_11676\\2209103747.py:3: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function\n",
    "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50050048]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to check the sentiment of your own tweet below\n",
    "my_tweet = 'I am learning nlp how badass'\n",
    "predict_tweet(my_tweet, freqs, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        test_x: a list of tweets\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        theta: weight vector of dimension (3, 1)\n",
    "    Output: \n",
    "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # the list for storing predictions\n",
    "    y_hat = []\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        # get the label prediction for the tweet\n",
    "        y_pred = predict_tweet(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            # append 1.0 to the list\n",
    "            y_hat.append(1.0)\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0.0)\n",
    "\n",
    "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
    "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
    "    y_hat = np.asarray(y_hat)\n",
    "    test_y = np.squeeze(test_y)\n",
    "    accuracy = (y_hat==test_y).sum()/len(test_y)\n",
    "\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.9950\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicted Tweet\n",
      "THE TWEET IS: @jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp\n",
      "THE PROCESSED TWEET IS: ['truli', 'later', 'move', 'know', 'queen', 'bee', 'upward', 'bound', 'movingonup']\n",
      "1\t0.49996920\tb'truli later move know queen bee upward bound movingonup'\n",
      "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
      "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
      "1\t0.48663815\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots\n",
      "http://t.co/UGQzOx0huu\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48370697\tb\"i'm play brain dot braindot\"\n",
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48370697\tb\"i'm play brain dot braindot\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rcata\\AppData\\Local\\Temp\\ipykernel_11676\\289099189.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
      "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
      "1\t0.48370697\tb\"i'm play brain dot braindot\"\n",
      "THE TWEET IS: off to the park to get some sunlight : )\n",
      "THE PROCESSED TWEET IS: ['park', 'get', 'sunlight']\n",
      "1\t0.49578796\tb'park get sunlight'\n",
      "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "1\t0.48212905\tb'uff itna miss karhi thi ap :p'\n",
      "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
      "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
      "0\t0.50020391\tb'u prob fun david'\n",
      "THE TWEET IS: pats jay : (\n",
      "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
      "0\t0.50039295\tb'pat jay'\n",
      "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
      "0\t0.50000002\tb'belov grandmoth'\n"
     ]
    }
   ],
   "source": [
    "# Some error analysis done for you\n",
    "print('Label Predicted Tweet')\n",
    "for x,y in zip(test_x,test_y):\n",
    "    y_hat = predict_tweet(x, freqs, theta)\n",
    "\n",
    "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
    "        print('THE TWEET IS:', x)\n",
    "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
    "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
      "[[0.48139084]]\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the tweet below\n",
    "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_omdena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
